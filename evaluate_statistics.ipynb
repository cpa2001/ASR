{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import whisper\n",
    "# import torch\n",
    "# import multiprocessing as mp\n",
    "\n",
    "# try:\n",
    "#     mp.set_start_method('spawn')\n",
    "# except RuntimeError:\n",
    "#     pass\n",
    "\n",
    "# folder_path = \"/home/pachen/dataset/Audio2Caption_Demo/alice's group/Nov 23, 2021 1026 AM\"\n",
    "# audio_folder = os.path.join(folder_path, \"cut_audio_segments_flac\")\n",
    "# original_json_path = os.path.join(folder_path, \"GMT20211123-022650_Recording.json\")\n",
    "\n",
    "# with open(original_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#     original_data = json.load(f)\n",
    "\n",
    "# file_paths = [os.path.join(audio_folder, file) for file in os.listdir(audio_folder) if file.endswith(\".flac\")]\n",
    "\n",
    "# num_gpus = torch.cuda.device_count()\n",
    "# pool = mp.Pool(processes=num_gpus)\n",
    "\n",
    "# def process_file(rank, file_paths):\n",
    "#     device = f\"cuda:{rank}\"\n",
    "#     torch.cuda.set_device(device)\n",
    "\n",
    "#     model = whisper.load_model(\"large-v3\", device=device)\n",
    "\n",
    "#     for file_path in file_paths:\n",
    "#         file_number = int(os.path.splitext(os.path.basename(file_path))[0])\n",
    "\n",
    "#         # 加载音频文件\n",
    "#         audio = whisper.load_audio(file_path)\n",
    "\n",
    "#         # 调用 Whisper 模型进行推理\n",
    "#         audio = whisper.pad_or_trim(audio)\n",
    "#         mel = whisper.log_mel_spectrogram(audio).to(device)\n",
    "#         _, decoded_options, _ = model.detect_language(mel)\n",
    "#         result = model.transcribe(mel, language=\"cantonese\", **decoded_options)\n",
    "\n",
    "#         # 查找对应的原始字幕条目\n",
    "#         original_entry = next((entry for entry in original_data if int(entry[\"id\"]) == file_number), None)\n",
    "\n",
    "#         if original_entry:\n",
    "#             # 在原始字幕条目中添加 Whisper 的 ASR 结果\n",
    "#             original_entry[\"whisper_sentence\"] = result[\"text\"]\n",
    "\n",
    "# # 将文件路径平均分配到每个进程\n",
    "# file_paths_per_process = [[] for _ in range(num_gpus)]\n",
    "# for i, file_path in enumerate(file_paths):\n",
    "#     file_paths_per_process[i % num_gpus].append(file_path)\n",
    "\n",
    "# # 并行处理文件\n",
    "# args = [(rank, paths) for rank, paths in enumerate(file_paths_per_process)]\n",
    "# pool.starmap(process_file, args)\n",
    "\n",
    "# # 关闭进程池\n",
    "# pool.close()\n",
    "# pool.join()\n",
    "\n",
    "# # 将修改后的数据写入新的 JSON 文件\n",
    "# output_json_path = os.path.join(folder_path, f\"GMT20211123-022650_Recording_whisper.json\")\n",
    "# with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(original_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据多个文件计算CER，新的inference不用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更新完成，新文件已保存至：/home/pachen/dataset/Audio2Caption_Demo/alice's group/Nov 23, 2021 1026 AM/GMT20211123-022650_Recording_with_whisper.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 路径设置\n",
    "original_json_path = '/home/pachen/dataset/Audio2Caption_Demo/alice\\'s group/Nov 23, 2021 1026 AM/GMT20211123-022650_Recording.json'\n",
    "whisper_json_path = '/home/pachen/dataset/ASR/output.json'\n",
    "\n",
    "# 读取原始JSON文件\n",
    "with open(original_json_path, 'r', encoding='utf-8') as file:\n",
    "    original_data = json.load(file)\n",
    "\n",
    "# 读取whisper JSON文件\n",
    "with open(whisper_json_path, 'r', encoding='utf-8') as file:\n",
    "    whisper_data = json.load(file)\n",
    "\n",
    "# 更新原始数据\n",
    "for item in original_data:\n",
    "    # 获取ID，并转换为字符串格式，以匹配whisper JSON中的键\n",
    "    item_id = str(item['id'])\n",
    "    # 如果此ID在whisper数据中存在，则添加whisper字段\n",
    "    if item_id in whisper_data:\n",
    "        item['whisper'] = whisper_data[item_id]['text']\n",
    "\n",
    "# 写回更新后的数据到一个新文件\n",
    "new_json_path = original_json_path.replace('.json', '_with_whisper.json')\n",
    "with open(new_json_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(original_data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f'更新完成，新文件已保存至：{new_json_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CER: 0.7922906513070448\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import Levenshtein as lev\n",
    "import re\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "def calculate_cer(reference, hypothesis):\n",
    "    distance = lev.distance(reference, hypothesis)\n",
    "    max_len = max(len(reference), len(hypothesis))\n",
    "    if max_len == 0:\n",
    "        return 0\n",
    "    return distance / max_len\n",
    "\n",
    "def transform_and_calculate_metrics(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    total_distance = 0\n",
    "    total_reference_len = 0\n",
    "\n",
    "    for item in data:\n",
    "        reference = remove_punctuation(item.get('sentence', '')).replace(\" \", \"\")\n",
    "        hypothesis = remove_punctuation(item.get('whisper', '')).replace(\" \", \"\")\n",
    "        distance = lev.distance(reference, hypothesis)\n",
    "        total_distance += distance\n",
    "        total_reference_len += len(reference)\n",
    "        item_cer = calculate_cer(reference, hypothesis) if len(reference) > 0 else 0\n",
    "        item['cer'] = item_cer\n",
    "\n",
    "    average_cer = total_distance / total_reference_len if total_reference_len > 0 else 0\n",
    "\n",
    "    new_json_path = json_path.replace('.json', '_metrics.json')\n",
    "    with open(new_json_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    return average_cer\n",
    "\n",
    "json_path = \"/home/pachen/dataset/Audio2Caption_Demo/alice's group/Nov 23, 2021 1026 AM/GMT20211123-022650_Recording_with_whisper.json\"\n",
    "average_cer = transform_and_calculate_metrics(json_path)\n",
    "print(f'Average CER: {average_cer}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总CER，仅计算中文字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER: 0.6305530372\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "def clean_text(text):\n",
    "    return \"\".join(re.findall(r'[\\u4e00-\\u9fff]', text))\n",
    "\n",
    "def calculate_cer(json_file_path):\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    total_ref_len = 0\n",
    "    total_edit_distance = 0\n",
    "    \n",
    "    for item in data:\n",
    "        ref_text = clean_text(item['sentence'])\n",
    "        hyp_text = clean_text(item['whisper'])\n",
    "        \n",
    "        total_ref_len += len(ref_text)\n",
    "        total_edit_distance += levenshtein_distance(ref_text, hyp_text)\n",
    "    \n",
    "    cer = total_edit_distance / total_ref_len if total_ref_len > 0 else 0\n",
    "    return cer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    json_file_path = \"/home/pachen/dataset/Audio2Caption_Demo/alice's group/Nov 23, 2021 1026 AM/GMT20211123-022650_Recording_30s_whisper.json\"  # 更改为你的文件路径\n",
    "    cer = calculate_cer(json_file_path)\n",
    "    print(f\"CER: {cer:.10f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总CER，忽略所有标点和空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER: 0.6310473153\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[\\s,.，。]', '', text)\n",
    "\n",
    "def levenshtein_distance(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]\n",
    "\n",
    "def calculate_cer(json_file_path):\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    total_ref_len = 0\n",
    "    total_edit_distance = 0\n",
    "    \n",
    "    for item in data:\n",
    "        ref_text = clean_text(item['sentence'])\n",
    "        hyp_text = clean_text(item['whisper'])\n",
    "        \n",
    "        total_ref_len += len(ref_text)\n",
    "        total_edit_distance += levenshtein_distance(ref_text, hyp_text)\n",
    "    \n",
    "    cer = total_edit_distance / total_ref_len if total_ref_len > 0 else 0\n",
    "    return cer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    json_file_path = \"/home/pachen/dataset/Audio2Caption_Demo/alice\\'s group/Nov 23, 2021 1026 AM/GMT20211123-022650_Recording_30s_whisper.json\"\n",
    "    cer = calculate_cer(json_file_path)\n",
    "    print(f\"CER: {cer:.10f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
