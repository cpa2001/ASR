{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 都算\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"large-v3\")\n",
    "result = model.transcribe(\"/home/pachen/dataset/Audio2Caption_Demo/alice's group/Nov 23, 2021 1026 AM/cut_audio_segments_flac/3.flac\",language='yue')\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import whisper\n",
    "\n",
    "# 加载Whisper模型\n",
    "model = whisper.load_model(\"large-v3\")\n",
    "\n",
    "def transcribe_directory(directory_path):\n",
    "    # 遍历文件夹内所有的.flac文件\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".flac\"):\n",
    "            # 构建完整的文件路径\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            \n",
    "            # 调用Whisper模型进行语音转写\n",
    "            result = model.transcribe(file_path, language=\"Cantonese(HK)\")  \n",
    "            print(f\"Transcription of {filename}: {result['text']}\")\n",
    "\n",
    "\n",
    "directory_path = \"/path/to/flac\"\n",
    "transcribe_directory(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "folder_path = \"/home/pachen/dataset/Audio2Caption_Demo/alice's group/Nov 23, 2021 1026 AM/cut_audio_segments_flac\"\n",
    "\n",
    "results = {}\n",
    "\n",
    "# 遍历文件夹,获取所有.flac文件路径\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".flac\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_number = int(file.split(\".\")[0])  # 获取文件序号\n",
    "\n",
    "            # 调用 model.transcribe 方法获取结果\n",
    "            result = model.transcribe(file_path, language=\"cantonese\")\n",
    "\n",
    "            # 将结果添加到字典中\n",
    "            results[file_number] = result\n",
    "\n",
    "# 将字典写入JSON文件\n",
    "with open(\"output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以跑这个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import timedelta\n",
    "import whisper\n",
    "\n",
    "folder_path = \"/home/pachen/dataset/Audio2Caption_Demo/alice's group/Nov 23, 2021 1026 AM\"\n",
    "\n",
    "# 初始化 Whisper 模型\n",
    "model = whisper.load_model(\"large-v3\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# 读取原始字幕文件\n",
    "original_json_path = os.path.join(folder_path, \"GMT20211123-022650_Recording.json\")\n",
    "with open(original_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    original_data = json.load(f)\n",
    "\n",
    "for root, dirs, files in os.walk(os.path.join(folder_path, \"cut_audio_segments_flac\")):\n",
    "    for file in files:\n",
    "        if file.endswith(\".flac\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_number = int(file.split(\".\")[0])  # 获取文件序号\n",
    "\n",
    "            # 调用 Whisper 模型进行推理\n",
    "            result = model.transcribe(file_path, language=\"cantonese\")[\"text\"]\n",
    "\n",
    "            # 查找对应的原始字幕条目\n",
    "            original_entry = next((entry for entry in original_data if int(entry[\"id\"]) == file_number), None)\n",
    "\n",
    "            if original_entry:\n",
    "                # 计算 CER\n",
    "                import jiwer\n",
    "                \n",
    "                ground_truth = original_entry[\"sentence\"]\n",
    "                hypothesis = result\n",
    "                \n",
    "                error = jiwer.cer(ground_truth, hypothesis)\n",
    "\n",
    "                # 创建新的字幕条目\n",
    "                new_entry = {\n",
    "                    \"id\": str(file_number),\n",
    "                    \"start_time\": original_entry[\"start_time\"],\n",
    "                    \"end_time\": original_entry[\"end_time\"],\n",
    "                    \"duration\": original_entry[\"duration\"],\n",
    "                    \"speaker\": original_entry[\"speaker\"],\n",
    "                    \"sentence\": original_entry[\"sentence\"],\n",
    "                    \"whisper\": result,\n",
    "                    \"cer\": error\n",
    "                }\n",
    "                results.append(new_entry)\n",
    "\n",
    "results.sort(key=lambda x: int(x[\"id\"]))\n",
    "\n",
    "# 将结果写入 JSON 文件\n",
    "output_json_path = os.path.join(folder_path, \"GMT20211123-022650_Recording_whisper.json\")\n",
    "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对齐output和输入，这个不用跑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import editdistance\n",
    "\n",
    "def compute_cer_wer(original_json_path, asr_json_path):\n",
    "    with open(original_json_path, 'r', encoding='utf-8') as f:\n",
    "        original_data = json.load(f)\n",
    "    with open(asr_json_path, 'r', encoding='utf-8') as f:\n",
    "        asr_data = json.load(f)\n",
    "\n",
    "    total_chars = 0\n",
    "    total_words = 0\n",
    "    char_errors = 0\n",
    "    word_errors = 0\n",
    "    char_weighted_errors = 0\n",
    "    word_weighted_errors = 0\n",
    "\n",
    "    for original_entry, asr_entry in zip(original_data, asr_data):\n",
    "        original_sentence = original_entry['sentence']\n",
    "        asr_sentence = asr_entry['sentence']\n",
    "\n",
    "        original_chars = len(original_sentence)\n",
    "        original_words = len(original_sentence.split())\n",
    "\n",
    "        total_chars += original_chars\n",
    "        total_words += original_words\n",
    "\n",
    "        char_distance = editdistance.eval(original_sentence, asr_sentence)\n",
    "        char_errors += char_distance\n",
    "        char_weighted_errors += char_distance * original_chars\n",
    "\n",
    "        original_word_list = original_sentence.split()\n",
    "        asr_word_list = asr_sentence.split()\n",
    "        word_distance = editdistance.eval(original_word_list, asr_word_list)\n",
    "        word_errors += word_distance\n",
    "        word_weighted_errors += word_distance * original_words\n",
    "\n",
    "    cer = char_errors / total_chars if total_chars > 0 else 0\n",
    "    wer = word_errors / total_words if total_words > 0 else 0\n",
    "    char_weighted_cer = char_weighted_errors / total_chars if total_chars > 0 else 0\n",
    "    word_weighted_wer = word_weighted_errors / total_words if total_words > 0 else 0\n",
    "\n",
    "    return cer, wer, char_weighted_cer, word_weighted_wer\n",
    "\n",
    "original_json_path = \"/home/pachen/dataset/Audio2Caption_Demo/alice's group/Nov 23, 2021 1026 AM/GMT20211123-022650_Recording.json\"\n",
    "asr_json_path = \"/home/pachen/dataset/Audio2Caption_Demo/alice's group/Nov 23, 2021 1026 AM/GMT20211123-022650_Recording_whisper.json\"\n",
    "\n",
    "compute_cer_wer(original_json_path, asr_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选GPU跑，whisper不支持多卡并行加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import timedelta\n",
    "import whisper\n",
    "import torch\n",
    "\n",
    "# 设置使用的GPU\n",
    "devices = [3]\n",
    "\n",
    "folder_path = \"/home/pachen/dataset/Audio2Caption_Demo/alice's group/Nov 23, 2021 1026 AM\"\n",
    "\n",
    "# 初始化 Whisper 模型\n",
    "model = whisper.load_model(\"large-v3\", device=f\"cuda:{devices[0]}\")\n",
    "\n",
    "model = torch.nn.DataParallel(model, device_ids=devices)\n",
    "\n",
    "results = []\n",
    "\n",
    "# 读取原始字幕文件\n",
    "original_json_path = os.path.join(folder_path, \"GMT20211123-022650_Recording30s.json\")\n",
    "with open(original_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    original_data = json.load(f)\n",
    "\n",
    "for root, dirs, files in os.walk(os.path.join(folder_path, \"cut_audio_segments_flac_30s\")):\n",
    "    for file in files:\n",
    "        if file.endswith(\".flac\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_number = int(file.split(\".\")[0])  # 获取文件序号\n",
    "\n",
    "            # 调用 Whisper 模型进行推理\n",
    "            result = model.module.transcribe(file_path, language=\"cantonese\")[\"text\"]\n",
    "\n",
    "            # 查找对应的原始字幕条目\n",
    "            original_entry = next((entry for entry in original_data if int(entry[\"id\"]) == file_number), None)\n",
    "\n",
    "            if original_entry:\n",
    "                # 计算 CER\n",
    "                import jiwer\n",
    "                \n",
    "                ground_truth = original_entry[\"sentence\"]\n",
    "                hypothesis = result\n",
    "                \n",
    "                error = jiwer.cer(ground_truth, hypothesis)\n",
    "\n",
    "                # 创建新的字幕条目\n",
    "                new_entry = {\n",
    "                    \"id\": str(file_number),\n",
    "                    \"start_time\": original_entry[\"start_time\"],\n",
    "                    \"end_time\": original_entry[\"end_time\"],\n",
    "                    \"duration\": original_entry[\"duration\"],\n",
    "                    # \"speaker\": original_entry[\"speaker\"],\n",
    "                    \"sentence\": original_entry[\"sentence\"],\n",
    "                    \"whisper\": result,\n",
    "                    \"cer\": error\n",
    "                }\n",
    "                results.append(new_entry)\n",
    "\n",
    "# 按 id 对结果列表进行排序\n",
    "results.sort(key=lambda x: int(x[\"id\"]))\n",
    "\n",
    "# 将结果写入 JSON 文件\n",
    "output_json_path = os.path.join(folder_path, \"GMT20211123-022650_Recording_30s_whisper.json\")\n",
    "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
